{
 "cells": [
  {
   "cell_type": "code",
   "id": "149d3606-0293-410b-8a90-c7f3425c0be5",
   "metadata": {
    "id": "149d3606-0293-410b-8a90-c7f3425c0be5",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.105244Z",
     "start_time": "2024-11-04T19:49:25.085240Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "id": "futDouavDOA0",
   "metadata": {
    "id": "futDouavDOA0"
   },
   "source": [
    "# **Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ASwb7GBDUzZ",
   "metadata": {
    "id": "0ASwb7GBDUzZ"
   },
   "source": [
    "## Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "id": "RIGAmsfBvD1E",
   "metadata": {
    "id": "RIGAmsfBvD1E",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.125920Z",
     "start_time": "2024-11-04T19:49:25.121512Z"
    }
   },
   "source": [
    "def get_X_y(file_path):\n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    # Map the first column ('e', 'p') to binary values\n",
    "    data[0] = data[0].apply(lambda x: 1 if x == 'p' else 0)  # 1 for poisonous, 0 for edible\n",
    "    X = pd.get_dummies(data.iloc[:, 1:])  # one hot encoding\n",
    "    y = data[0]\n",
    "    return X, y\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "id": "CjKaxX68DQye",
   "metadata": {
    "id": "CjKaxX68DQye",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.191845Z",
     "start_time": "2024-11-04T19:49:25.148407Z"
    }
   },
   "source": [
    "#file_path = 'https://archive.ics.uci.edu/static/public/73/data.csv'\n",
    "\n",
    "file_path = \"./agaricus-lepiota.data\"\n",
    "\n",
    "X, y = get_X_y(file_path)\n",
    "print(X, y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1_b    1_c    1_f    1_k    1_s    1_x    2_f    2_g    2_s    2_y  \\\n",
      "0     False  False  False  False  False   True  False  False   True  False   \n",
      "1     False  False  False  False  False   True  False  False   True  False   \n",
      "2      True  False  False  False  False  False  False  False   True  False   \n",
      "3     False  False  False  False  False   True  False  False  False   True   \n",
      "4     False  False  False  False  False   True  False  False   True  False   \n",
      "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "8119  False  False  False   True  False  False  False  False   True  False   \n",
      "8120  False  False  False  False  False   True  False  False   True  False   \n",
      "8121  False  False   True  False  False  False  False  False   True  False   \n",
      "8122  False  False  False   True  False  False  False  False  False   True   \n",
      "8123  False  False  False  False  False   True  False  False   True  False   \n",
      "\n",
      "      ...   21_s   21_v   21_y   22_d   22_g   22_l   22_m   22_p   22_u  \\\n",
      "0     ...   True  False  False  False  False  False  False  False   True   \n",
      "1     ...  False  False  False  False   True  False  False  False  False   \n",
      "2     ...  False  False  False  False  False  False   True  False  False   \n",
      "3     ...   True  False  False  False  False  False  False  False   True   \n",
      "4     ...  False  False  False  False   True  False  False  False  False   \n",
      "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "8119  ...  False  False  False  False  False   True  False  False  False   \n",
      "8120  ...  False   True  False  False  False   True  False  False  False   \n",
      "8121  ...  False  False  False  False  False   True  False  False  False   \n",
      "8122  ...  False   True  False  False  False   True  False  False  False   \n",
      "8123  ...  False  False  False  False  False   True  False  False  False   \n",
      "\n",
      "       22_w  \n",
      "0     False  \n",
      "1     False  \n",
      "2     False  \n",
      "3     False  \n",
      "4     False  \n",
      "...     ...  \n",
      "8119  False  \n",
      "8120  False  \n",
      "8121  False  \n",
      "8122  False  \n",
      "8123  False  \n",
      "\n",
      "[8124 rows x 117 columns] 0       1\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "8119    0\n",
      "8120    0\n",
      "8121    0\n",
      "8122    1\n",
      "8123    0\n",
      "Name: 0, Length: 8124, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "id": "H3F-tDrSweAO",
   "metadata": {
    "id": "H3F-tDrSweAO"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K3KCtV49xfcC",
   "metadata": {
    "id": "K3KCtV49xfcC"
   },
   "source": [
    "### 1. Initialize the parameters\n",
    "init weight and biases, since we have 22 features, but after one hot encoding, the dimension of feature becames x.shape[1], so we are going to generate s.shape[1] random features and a single bias."
   ]
  },
  {
   "cell_type": "code",
   "id": "M9yiCcfwxBnr",
   "metadata": {
    "id": "M9yiCcfwxBnr",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.215328Z",
     "start_time": "2024-11-04T19:49:25.212319Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "NUM_OF_FEATURES = X.shape[1]\n",
    "weights = np.random.random(NUM_OF_FEATURES)\n",
    "bias = 0  # I randomly init as zero\n",
    "learning_rate = 0.01\n",
    "epochs = 10 ** 3"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "id": "2pUljgKkxVCO",
   "metadata": {
    "id": "2pUljgKkxVCO"
   },
   "source": [
    "### 2. Define the Prediction Function\n",
    "$$\n",
    "\\Huge P(x) = \\frac{1}{1+e^{-(x \\cdot weights + bias)}}\n",
    "$$\n",
    "x is the input of features, weight is the matrix of weight for all features, P(x) is the Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "id": "N319PLsmxZbe",
   "metadata": {
    "id": "N319PLsmxZbe",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.231787Z",
     "start_time": "2024-11-04T19:49:25.228671Z"
    }
   },
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "# prediction function\n",
    "def pred(x, p_weights, p_bias):\n",
    "    return sigmoid(np.dot(x, p_weights) + p_bias)\n",
    "\n",
    "\n",
    "def classify(x, cl_weights, cl_bias, threshold=0.5):\n",
    "    y_pred = pred(x, cl_weights, cl_bias)\n",
    "    return [1 if p >= threshold else 0 for p in y_pred]"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "id": "XYLS9ruWxiwB",
   "metadata": {
    "id": "XYLS9ruWxiwB"
   },
   "source": [
    "### 3. Define the Loss Function (Cross-Entropy)\n",
    "$$\n",
    "\\Huge L = -\\sum_{k=1}^{K} \\left( y_k \\ln(p_k) + (1 - y_k) \\ln(1 - p_k) \\right)\n",
    "$$\n",
    "y means the true label, and p means the prediction"
   ]
  },
  {
   "cell_type": "code",
   "id": "_XIwas2jxmBk",
   "metadata": {
    "id": "_XIwas2jxmBk",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.244067Z",
     "start_time": "2024-11-04T19:49:25.242060Z"
    }
   },
   "source": [
    "def compute_loss(y, y_pred):\n",
    "    return - np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred))"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "id": "Ry88hKfVxpaF",
   "metadata": {
    "id": "Ry88hKfVxpaF"
   },
   "source": [
    "### 4. Gradient Descent\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "Eb9pAFvVxrzY",
   "metadata": {
    "id": "Eb9pAFvVxrzY",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:25.257547Z",
     "start_time": "2024-11-04T19:49:25.254138Z"
    }
   },
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"train.log\",\n",
    "    filemode=\"a\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "\n",
    "def gradient_descent(x, y, gd_weights, gd_bias, gd_learning_rate, gd_epochs):\n",
    "    n = len(y)\n",
    "    logging.info('Start training ---')\n",
    "    for eee in range(gd_epochs):\n",
    "        y_pred = pred(x, gd_weights, gd_bias)\n",
    "\n",
    "        dw = (1 / n) * np.dot(x.T, (y_pred - y))\n",
    "        db = (1 / n) * np.sum(y_pred - y)\n",
    "\n",
    "        gd_weights -= gd_learning_rate * dw\n",
    "        gd_bias -= gd_learning_rate * db\n",
    "\n",
    "        if eee % 100 == 0:\n",
    "            loss = compute_loss(y, y_pred)\n",
    "            logging.info(f\"Epoch {eee}/{gd_epochs}, Loss: {loss}\\n\")\n",
    "\n",
    "    return gd_weights, gd_bias"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "id": "Oa0q46Edxyhl",
   "metadata": {
    "id": "Oa0q46Edxyhl"
   },
   "source": [
    "### 5. Model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07xQGFalEsdC",
   "metadata": {
    "id": "07xQGFalEsdC"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ZRCCuQUkxzu1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZRCCuQUkxzu1",
    "outputId": "dbaa6c3c-88bb-439a-ef1e-7bdc9690045d",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:39.803912Z",
     "start_time": "2024-11-04T19:49:25.267658Z"
    }
   },
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# K-Fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "accuracies = []\n",
    "\n",
    "# K-Fold Loop\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data\n",
    "    X_train, X_test = X.iloc[train_index].values, X.iloc[test_index].values\n",
    "    y_train, y_test = y.iloc[train_index].values, y.iloc[test_index].values\n",
    "\n",
    "    # Train the model using gradient descent\n",
    "    weights = np.random.random(NUM_OF_FEATURES)\n",
    "    bias = 0\n",
    "    weights, bias = gradient_descent(X_train, y_train, weights, bias, learning_rate, epochs)\n",
    "    print(weights, bias)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = classify(X_test, weights, bias)\n",
    "\n",
    "    # Calculate accuracy and append to the list\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(accuracies)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.57730831  0.62279728  0.41875838  0.75064014  0.24421362  0.32328039\n",
      "  0.10696619  0.30234054  0.45183328  0.51024452  0.40375171  0.80303516\n",
      "  0.41524028 -0.14972021  0.17402072  0.96440045  0.5291486   0.06993429\n",
      "  0.02366402 -0.02832354  0.32170319 -0.28198105  0.39612915  0.1711821\n",
      "  1.26456701  0.16752359  0.37213415 -0.61378934  0.57229757  0.10175445\n",
      "  0.75177463  0.34705026 -0.42393877  0.2012905  -0.42778063 -0.65301414\n",
      "  0.96715437  0.5393104  -0.03334017  0.32712526  0.3096324   0.06101794\n",
      "  0.25723102  0.53201918  0.35033848  0.19266288  0.75194455  0.17800564\n",
      "  0.78699953 -0.39311408 -0.1988687   0.33986023  0.08047478  0.0239133\n",
      "  0.36827281  0.24132175  0.60436751  0.82317996 -0.18447523  0.55783315\n",
      "  0.42969914  0.51059429 -0.34944128  0.78705689  0.48979691  0.98452589\n",
      "  0.46874211 -0.06231946  0.34344994  0.01606865  0.82396666  0.08604841\n",
      "  0.10647913  1.00939145  0.57400271 -0.03152603  0.31824275  0.87006193\n",
      "  0.15156959  0.58964266  0.41558016  0.54176306 -0.39531101  0.19993399\n",
      "  0.48712723 -0.73052876  0.33342308  0.39123678 -0.51585625 -0.19325408\n",
      "  0.13371998 -0.0184338   0.79759359  0.15944864 -0.15698859  0.47094652\n",
      "  0.66853888  0.33735765  0.38717479  0.38377437  0.88776262 -0.00290512\n",
      "  0.1761339   0.90618998 -0.03376279 -0.0933146   0.58014567  0.14334476\n",
      "  0.21542622 -0.20248442 -0.14882242  0.22901592  0.61333951  0.37069557\n",
      "  0.83988867  0.20179404  0.63033465] -1.0131222905429316\n",
      "[ 0.44398021  0.37517173  0.61423675  0.2937869   0.52880968  0.10976293\n",
      " -0.30097494  0.85036119 -0.04503266 -0.17529763  0.34196159  0.16216756\n",
      "  0.56371705  0.10049589 -0.04951112  0.09004877  0.89293939  0.29332408\n",
      "  0.34542716  0.37925768 -0.04692925 -0.42514037  0.54216963  0.16660585\n",
      "  0.77566372  0.76217872  0.93997754 -1.07696018  0.41507314  0.34458109\n",
      "  0.91059029  0.52531206  0.28052341  0.24114242  0.12965917 -0.61480862\n",
      "  0.72022336  0.4795396   0.1537787   0.73325314  0.48339165  0.51169101\n",
      "  0.04524042  0.66055247  0.09475929  0.72689672  0.05465628  0.25821755\n",
      "  0.46949871 -0.18776389  0.0912958   0.44608192 -0.01738573  0.51892369\n",
      "  0.35224546  0.32808003  0.80130766  0.24941614 -0.38394604  0.47319237\n",
      "  0.02503796  0.65123116  0.11808239  0.61792851  0.75397069  0.55200713\n",
      "  0.66905494 -0.00296114  0.62712549  0.21042124  0.65957205 -0.27192869\n",
      "  0.6369617   0.90096355  0.31691182  0.78342305  0.42953645  0.80888584\n",
      "  0.43660984  0.59046552 -0.28002381  0.22666541 -0.56797953  0.5344563\n",
      "  0.51053429 -0.5155218   0.21938882  0.90443533 -0.48080188  0.53334198\n",
      "  0.08732801  0.03411381  0.94249503  0.16503631  0.04854835  0.42489494\n",
      "  0.82855069  0.08726887  0.01711376  0.04807544  0.48153468  0.35413176\n",
      "  0.10374193  0.33149445  0.61852515  0.45148483  0.26904254  0.47180049\n",
      "  0.89619961  0.02023825 -0.1417477  -0.12416531 -0.03212495  0.62056141\n",
      "  0.22935711  0.38801463  0.41874897] -0.8112423495682176\n",
      "[-0.02412026  0.65365261  0.53220281  0.71290465  0.0570834   0.4502998\n",
      "  0.38405066  0.01844448  0.51263164  0.19604546  0.52567131  0.3139913\n",
      "  0.29259136 -0.09442949 -0.06439397  0.4253392   0.12748782  0.98056548\n",
      " -0.03214418  0.68172711  0.2544372   0.20831887  0.19552912  0.93369331\n",
      "  1.16180432 -0.00759154  0.86252265 -0.89856055  0.96994625  0.45150942\n",
      "  0.3415591   0.03352555 -0.3583535   0.26355095 -0.16696302 -0.92568542\n",
      "  1.16145865  0.24326449  0.47903922  0.4935251   0.75648994  0.59049746\n",
      "  0.10540282  0.20465378  0.06895797  0.27152127  0.59777385 -0.17282858\n",
      "  0.37640708 -0.29559868 -0.13866419  0.10942023 -0.08236741  0.26983503\n",
      "  0.43722593  0.69349641  0.73767082  0.46044737 -0.02815838  0.2643834\n",
      " -0.08123619  0.78739339 -0.60134812  0.36190264  0.79759267  0.03927296\n",
      "  0.20248668  0.6662669   0.16876448  0.71922967  0.04088599 -0.27225446\n",
      "  0.35784023  0.73879785  0.08477498  0.13779184  0.44078866  0.27587902\n",
      "  0.40667751  0.01671714  0.0403203   0.85267426 -0.10317366  0.09358359\n",
      "  0.77497209 -0.37332531  0.9958099   0.79652122 -0.2930439   0.77692122\n",
      "  0.07128743  0.06514734  0.75242621  0.63121925 -0.73811132  0.30994286\n",
      "  0.69555679 -0.03566677 -0.13219385  0.69539433  0.15540507  0.14793835\n",
      "  0.16005813  0.72026062  0.7006738   0.48206269  0.6410197   0.47425953\n",
      "  0.36955507  0.19852232  0.5203312  -0.26522533  0.48190055  0.83458555\n",
      "  0.56016248  0.9373928  -0.03079401] -0.9940616011539831\n",
      "[-0.11013314  0.95536208  0.40545258  0.71435144  0.65819645 -0.08571007\n",
      "  0.3507303   0.28532884  0.8011183   0.54363005  0.85503449  0.33295912\n",
      "  0.51792528  0.45733729  0.18376934  0.72929554  0.39892723  0.38222339\n",
      "  0.11736274  0.37868023  0.51121711  0.23153612  0.25289875  0.67812657\n",
      "  1.11256542  0.68083452  0.89055763 -0.78297538  0.99930226  0.65466639\n",
      "  0.32793649 -0.12819107 -0.53777606  0.05167291  0.37607008 -0.68218593\n",
      "  0.58083997  0.60654134  0.30855747  0.46390403  0.6173379  -0.03656494\n",
      "  0.37087813  0.31777491 -0.00348134  0.15638198  0.53883988 -0.03323127\n",
      "  0.41997207  0.16276802 -0.41383563  0.16406585 -0.03359217 -0.01997092\n",
      "  0.08336976  0.24592924  0.21093837  0.15862496 -0.3045412   0.20191677\n",
      "  0.48815836  0.39844151 -0.73094096  0.69253434  0.31542469  0.57176331\n",
      "  0.13460956  0.37551719  0.23541453  0.63551942  0.55311967 -0.46597967\n",
      "  0.7074135   0.80956858  0.13228507  0.33361438  0.31450004  0.27292192\n",
      "  0.48545681  0.7213096   0.3499351   0.15451622 -0.31852586  0.03890245\n",
      " -0.04709727 -0.04754617  0.69269276  0.17895218 -0.55550229 -0.21056886\n",
      "  0.47786447 -0.04510287  0.45607799  0.01079542 -0.27840232  0.71408255\n",
      "  0.62169568  0.39185564 -0.14889011  0.19107977  0.83770406  0.18104466\n",
      "  0.50727373  0.09489549  0.00710575 -0.11785947  0.21901283 -0.11257811\n",
      "  0.58694614 -0.20086211  0.45266594 -0.05743625  0.06191028  0.50684913\n",
      "  0.22483454  0.23481498  0.75983686] -1.0552367482371092\n",
      "[-0.06830359  0.05095106 -0.02525513  0.54093201  0.30171586  0.11559919\n",
      " -0.12740149  0.08151696  0.2029572  -0.1179977   0.64799545  0.13507645\n",
      " -0.01267585  0.06202154 -0.23771331  0.68877363  0.02649748  0.70589656\n",
      "  0.44129665  0.35524671 -0.17288501 -0.66609714  0.65842243  0.95627452\n",
      "  0.61164878  0.57276564  0.01174562 -0.77401048  0.87264455  1.05385988\n",
      "  0.91251557  0.52867363 -0.55861113  0.35945063 -0.23194285 -0.77116523\n",
      "  0.32010533  0.35239723  0.86414798  0.37377672  0.12732742  0.41436166\n",
      "  0.02420729  0.38328413  0.4998437   0.3438559   0.05706722  0.50382633\n",
      "  0.54123931  0.16489764  0.10808076  0.53594234  0.3724875   0.31568\n",
      "  0.80361423  0.15632904  0.14330691  0.57241401 -0.16511914  0.04611396\n",
      "  0.5022073   0.88763766 -0.06629031  0.582787    0.91940586  0.28142839\n",
      "  0.41614996 -0.06191323  0.15536046  0.57438759  0.386357   -0.09902334\n",
      "  0.98458898  0.14438959  0.23955574  0.26241674  0.49689973  0.66313992\n",
      "  0.70014074  0.89616601  0.26748546  0.60059324 -0.9851526   0.2536113\n",
      "  0.08092341 -0.02458771  0.84705465  0.28749291 -0.31523465  0.45962687\n",
      "  0.09127244  0.1437104   0.39702222  0.12837595 -0.20196352  0.61286844\n",
      "  0.90927457 -0.01735685 -0.06579214  0.61751558  0.57392866  0.66448163\n",
      "  0.72752395  0.35905377  0.08659907  0.55355996  0.67506782  0.65941198\n",
      "  0.38222788  0.5692838   0.29626887 -0.29962563  0.62139793  0.81421313\n",
      "  0.76772626  0.81595725  0.18142624] -0.9882568188389228\n",
      "[0.9181538461538462, 0.8990769230769231, 0.9403076923076923, 0.9243076923076923, 0.8971674876847291]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "id": "MPFNvC-JmOA3"
   },
   "id": "MPFNvC-JmOA3"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel='linear')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(svm_clf, X_test, y_test, cv=kf)\n",
    "\n",
    "print(scores)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gY_BF6MDmPva",
    "outputId": "d6aa89ef-ff95-412d-a57e-f4f01210cdcf",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:40.153676Z",
     "start_time": "2024-11-04T19:49:39.898229Z"
    }
   },
   "id": "gY_BF6MDmPva",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {
    "id": "i94ubJaymmH6"
   },
   "id": "i94ubJaymmH6"
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(max_depth=7)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(tree_clf, X_test, y_test, cv=kf)\n",
    "\n",
    "print(scores)\n",
    "\n",
    "tree.plot_tree(tree_clf)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 942
    },
    "id": "lXOZlsXtmolF",
    "outputId": "dc75f55e-4088-4bb2-eac8-ec7f1da3ace8",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:40.398768Z",
     "start_time": "2024-11-04T19:49:40.200483Z"
    }
   },
   "id": "lXOZlsXtmolF",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99795082 1.         1.         1.         1.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.5625, 0.9375, 'x[27] <= 0.5\\ngini = 0.499\\nsamples = 5686\\nvalue = [2972.0, 2714.0]'),\n",
       " Text(0.3125, 0.8125, 'x[53] <= 0.5\\ngini = 0.286\\nsamples = 3190\\nvalue = [551, 2639]'),\n",
       " Text(0.4375, 0.875, 'True  '),\n",
       " Text(0.1875, 0.6875, 'x[63] <= 0.5\\ngini = 0.134\\nsamples = 2817\\nvalue = [204, 2613]'),\n",
       " Text(0.125, 0.5625, 'x[34] <= 0.5\\ngini = 0.055\\nsamples = 2689\\nvalue = [76, 2613]'),\n",
       " Text(0.0625, 0.4375, 'gini = 0.0\\nsamples = 2551\\nvalue = [0, 2551]'),\n",
       " Text(0.1875, 0.4375, 'x[49] <= 0.5\\ngini = 0.495\\nsamples = 138\\nvalue = [76, 62]'),\n",
       " Text(0.125, 0.3125, 'gini = 0.0\\nsamples = 76\\nvalue = [76, 0]'),\n",
       " Text(0.25, 0.3125, 'gini = 0.0\\nsamples = 62\\nvalue = [0, 62]'),\n",
       " Text(0.25, 0.5625, 'gini = 0.0\\nsamples = 128\\nvalue = [128, 0]'),\n",
       " Text(0.4375, 0.6875, 'x[65] <= 0.5\\ngini = 0.13\\nsamples = 373\\nvalue = [347.0, 26.0]'),\n",
       " Text(0.375, 0.5625, 'gini = 0.0\\nsamples = 347\\nvalue = [347, 0]'),\n",
       " Text(0.5, 0.5625, 'gini = 0.0\\nsamples = 26\\nvalue = [0, 26]'),\n",
       " Text(0.8125, 0.8125, 'x[100] <= 0.5\\ngini = 0.058\\nsamples = 2496\\nvalue = [2421, 75]'),\n",
       " Text(0.6875, 0.875, '  False'),\n",
       " Text(0.75, 0.6875, 'x[63] <= 0.5\\ngini = 0.021\\nsamples = 2447\\nvalue = [2421, 26]'),\n",
       " Text(0.625, 0.5625, 'x[7] <= 0.5\\ngini = 0.002\\nsamples = 2412\\nvalue = [2409, 3]'),\n",
       " Text(0.5625, 0.4375, 'x[1] <= 0.5\\ngini = 0.002\\nsamples = 2411\\nvalue = [2409.0, 2.0]'),\n",
       " Text(0.5, 0.3125, 'x[35] <= 0.5\\ngini = 0.001\\nsamples = 2410\\nvalue = [2409, 1]'),\n",
       " Text(0.4375, 0.1875, 'x[21] <= 0.5\\ngini = 0.014\\nsamples = 143\\nvalue = [142, 1]'),\n",
       " Text(0.375, 0.0625, 'gini = 0.0\\nsamples = 142\\nvalue = [142, 0]'),\n",
       " Text(0.5, 0.0625, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.5625, 0.1875, 'gini = 0.0\\nsamples = 2267\\nvalue = [2267, 0]'),\n",
       " Text(0.625, 0.3125, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.6875, 0.4375, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.875, 0.5625, 'x[35] <= 0.5\\ngini = 0.451\\nsamples = 35\\nvalue = [12, 23]'),\n",
       " Text(0.8125, 0.4375, 'gini = 0.0\\nsamples = 23\\nvalue = [0, 23]'),\n",
       " Text(0.9375, 0.4375, 'gini = 0.0\\nsamples = 12\\nvalue = [12, 0]'),\n",
       " Text(0.875, 0.6875, 'gini = 0.0\\nsamples = 49\\nvalue = [0, 49]')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "id": "Z-b9pUqsyDop",
   "metadata": {
    "id": "Z-b9pUqsyDop"
   },
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jAwMsEc6yFuJ",
   "metadata": {
    "id": "jAwMsEc6yFuJ"
   },
   "source": [
    "### 1. Define the MLP Classifier\n",
    "\n",
    "define 2 hidden layers with 50 and 50 nodes, use relu as activation function, max iteration time is 1000"
   ]
  },
  {
   "cell_type": "code",
   "id": "x0K_hEGRyIgk",
   "metadata": {
    "id": "x0K_hEGRyIgk",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:40.426082Z",
     "start_time": "2024-11-04T19:49:40.421170Z"
    }
   },
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define the MLP model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(50, 50),\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    max_iter=100,\n",
    "                    random_state=10)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "id": "31kj52fCyKpb",
   "metadata": {
    "id": "31kj52fCyKpb"
   },
   "source": [
    "### 2. k-fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "id": "V7AfHwqdyNoo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7AfHwqdyNoo",
    "outputId": "c9103b68-0f1f-492d-91a5-916cb7d06b8f",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:49:49.436689Z",
     "start_time": "2024-11-04T19:49:40.449137Z"
    }
   },
   "source": [
    "cv_scores = cross_val_score(mlp, X, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation accuracies for each fold: {cv_scores}\")\n",
    "print(f\"Average cross-validation accuracy: {cv_scores.mean():.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracies for each fold: [1. 1. 1. 1. 1.]\n",
      "Average cross-validation accuracy: 1.00\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation"
   ],
   "metadata": {
    "id": "_nu_PAjpqiFL"
   },
   "id": "_nu_PAjpqiFL"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# K-Fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=10)\n",
    "accuracies_lg = []\n",
    "accuracies_svm = []\n",
    "accuracies_dt = []\n",
    "accuracies_nn = []\n",
    "\n",
    "# K-Fold Loop\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data\n",
    "    X_train, X_test = X.iloc[train_index].values, X.iloc[test_index].values\n",
    "    y_train, y_test = y.iloc[train_index].values, y.iloc[test_index].values\n",
    "\n",
    "    # Logistic Regression\n",
    "    # Train the model using gradient descent\n",
    "    weights = np.random.random(NUM_OF_FEATURES)\n",
    "    bias = 0\n",
    "    weights, bias = gradient_descent(X_train, y_train, weights, bias, learning_rate, epochs)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = classify(X_test, weights, bias)\n",
    "\n",
    "    # Calculate accuracy and append to the list\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies_lg.append(accuracy)\n",
    "\n",
    "    # SVM\n",
    "    svm_clf.fit(X_train, y_train)\n",
    "    accuracies_svm = cross_val_score(svm_clf, X_test, y_test, cv=kf)\n",
    "\n",
    "    # Decision Tree\n",
    "    tree_clf.fit(X_train, y_train)\n",
    "    accuracies_dt = cross_val_score(tree_clf, X_test, y_test, cv=kf)\n",
    "\n",
    "    # Neural Network\n",
    "    mlp.fit(X_train, y_train)\n",
    "    accuracies_nn = cross_val_score(mlp, X_test, y_test, cv=kf)\n",
    "\n",
    "print(\"Logistic regression's accuracies: \" + str(accuracies_lg))\n",
    "print(\"SVM's accuracies: \" + str(accuracies_svm))\n",
    "print(\"Decision tree's accuracies: \" + str(accuracies_dt))\n",
    "print(\"Neural network's accuracies: \" + str(accuracies_nn))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjqFq-upqj72",
    "outputId": "12142d57-cf34-4298-aace-797ce6e9196c",
    "ExecuteTime": {
     "end_time": "2024-11-04T19:52:53.503263Z",
     "start_time": "2024-11-04T19:52:23.379620Z"
    }
   },
   "id": "DjqFq-upqj72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression's accuracies: [0.9316923076923077, 0.8947692307692308, 0.912, 0.9403076923076923, 0.9144088669950738]\n",
      "SVM's accuracies: [1.         1.         1.         1.         0.99691358]\n",
      "Decision tree's accuracies: [0.99692308 0.99692308 1.         1.         0.99691358]\n",
      "Neural network's accuracies: [1.         1.         1.         1.         0.99691358]\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
